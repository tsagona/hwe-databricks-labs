{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 Lab: Bronze Layer\n",
    "\n",
    "In this lab you will build the Bronze layer of our bookstore's medallion architecture.\n",
    "\n",
    "You'll ingest four CSV files into Delta tables, adding audit columns and using MERGE INTO so the pipeline is idempotent — safe to run multiple times without creating duplicates.\n",
    "\n",
    "**A note on our source data:**\n",
    "- **Books and Stores** are static reference data — each is a single CSV file that won't change over time.\n",
    "- **Online Orders and In-Store Orders** are transactional data. New order files can arrive in their directories at any time, so `read_files` reads the entire directory to pick up any new files on each run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure the target Bronze tables exist. Run the DDL notebook at `ddl/bronze` to create them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load CSV Files into Temporary Views\n",
    "\n",
    "We read each source CSV into a temporary view. \n",
    "* For books and stores, we point at a single static file. \n",
    "* For both online and in-store orders, we point at a directory — `read_files` will read all CSVs in the directory, picking up any new files that have landed since the last run. \n",
    "\n",
    "We add two audit columns in each view:\n",
    "* `source_filename` — comes from the file metadata\n",
    "* `ingestion_timestamp` — set to `current_timestamp()` so we know when the data was loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Load Stores data into a Temporary View\nCREATE a temporary view named `stores_raw` which:\n* selects each column from the stores CSV file by name\n* adds `source_filename` from the file metadata\n* adds `ingestion_timestamp` set to the current time.\n\n\"Stores\" is a static data set for the duration of the labs - our bookstore has 8 physical locations, and we will not be opening or closing any locations as part of the coursework."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CREATE OR REPLACE TEMPORARY VIEW stores_raw AS\nSELECT\n  store_nbr,\n  store_name,\n  store_address,\n  store_city,\n  store_state,\n  store_zip,\n  current_timestamp() AS ingestion_timestamp,\n  _metadata.file_path AS source_filename\nFROM read_files(\n  '/FileStore/hwe-data/stores/stores.csv',\n  format => 'csv',\n  header => true\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Load Books data into a Temporary View\nCREATE a temporary view named `books_raw` which:\n* selects each column from the books CSV file by name\n* adds `source_filename` from the file metadata\n* adds `ingestion_timestamp` set to the current time.\n\n\"Books\" is a static data set for the duration of the labs - our bookstore has a catalog of 110 books, and we will not be adding or removing books from this catalog as part of the coursework."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CREATE OR REPLACE TEMPORARY VIEW books_raw AS\nSELECT\n  isbn,\n  title,\n  author,\n  genre,\n  current_timestamp() AS ingestion_timestamp,\n  _metadata.file_path AS source_filename\nFROM read_files(\n  '/FileStore/hwe-data/books/books.csv',\n  format => 'csv',\n  header => true\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Load Online Orders data into a Temporary View\nCREATE a temporary view named `online_orders_raw` which:\n* selects each column from the online orders CSV directory by name\n* adds `source_filename` from the file metadata\n* adds `ingestion_timestamp` set to the current time.\n\n\"Online Orders\" is transactional data - unlike books and stores, new order files can arrive in this directory at any time. `read_files` reads the entire directory so we always pick up every order we've ever received."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CREATE OR REPLACE TEMPORARY VIEW online_orders_raw AS\nSELECT\n  order_id,\n  order_timestamp,\n  customer_email,\n  customer_name,\n  customer_address,\n  customer_city,\n  customer_state,\n  customer_zip,\n  items,\n  payment_method,\n  total_amount,\n  current_timestamp() AS ingestion_timestamp,\n  _metadata.file_path AS source_filename\nFROM read_files(\n  '/FileStore/hwe-data/online_orders/',\n  format => 'csv',\n  header => true\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Load In-Store Orders data into a Temporary View\nCREATE a temporary view named `instore_orders_raw` which:\n* selects each column from the in-store orders CSV directory by name\n* adds `source_filename` from the file metadata\n* adds `ingestion_timestamp` set to the current time.\n\n\"In-Store Orders\" is transactional data - same as online orders, new order files can arrive at any time. Also like \"Online Orders\", `read_files` reads the entire directory so we always pick up every order we've ever received."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CREATE OR REPLACE TEMPORARY VIEW instore_orders_raw AS\nSELECT\n  order_id,\n  transaction_timestamp,\n  store_nbr,\n  customer_email,\n  items,\n  payment_method,\n  total_amount,\n  cashier_name,\n  current_timestamp() AS ingestion_timestamp,\n  _metadata.file_path AS source_filename\nFROM read_files(\n  '/FileStore/hwe-data/instore_orders/',\n  format => 'csv',\n  header => true\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Step 2: Load Data into Bronze Tables\n\nNow we load data from the temporary views into the bronze tables.\n\nFor **static reference data** (stores and books), we use `INSERT OVERWRITE` — this replaces the entire table contents each time. Since the source is a single, complete file, a full reload is the simplest approach and is naturally idempotent.\n\nFor **transactional data** (online orders and in-store orders), we use `MERGE INTO`, which matches rows on a natural key:\n- If a match is found → update the existing row\n- If no match → insert a new row\n\nThis makes our pipeline **idempotent** — running it again with the same data won't create duplicates."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Overwrite `bronze.stores` with the full contents of `stores_raw`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "INSERT OVERWRITE bronze.stores (store_nbr, store_name, store_address, store_city, store_state, store_zip, ingestion_timestamp, source_filename)\nSELECT\n  store_nbr,\n  store_name,\n  store_address,\n  store_city,\n  store_state,\n  store_zip,\n  ingestion_timestamp,\n  source_filename\nFROM stores_raw"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Overwrite `bronze.books` with the full contents of `books_raw`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "INSERT OVERWRITE bronze.books (isbn, title, author, genre, ingestion_timestamp, source_filename)\nSELECT\n  isbn,\n  title,\n  author,\n  genre,\n  ingestion_timestamp,\n  source_filename\nFROM books_raw"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `online_orders_raw` into `bronze.online_orders`, matching on `order_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGE INTO bronze.online_orders AS target\n",
    "USING online_orders_raw AS source\n",
    "ON target.order_id <=> source.order_id\n",
    "WHEN MATCHED THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN INSERT *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `instore_orders_raw` into `bronze.instore_orders`, matching on `order_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGE INTO bronze.instore_orders AS target\n",
    "USING instore_orders_raw AS source\n",
    "ON target.order_id <=> source.order_id\n",
    "WHEN MATCHED THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN INSERT *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Verify Idempotency\n",
    "\n",
    "Now go back and **run all the cells above a second time**. The MERGE should match every row and update it — no new rows should be inserted.\n",
    "\n",
    "Let's verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the row counts across all four bronze tables. These should be the same before and after the second run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT 'bronze.stores' AS table_name, COUNT(*) AS row_count FROM bronze.stores\n",
    "UNION ALL\n",
    "SELECT 'bronze.books', COUNT(*) FROM bronze.books\n",
    "UNION ALL\n",
    "SELECT 'bronze.online_orders', COUNT(*) FROM bronze.online_orders\n",
    "UNION ALL\n",
    "SELECT 'bronze.instore_orders', COUNT(*) FROM bronze.instore_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicate keys. This query should return **no rows**. If it returns anything, your MERGE key isn't working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT 'bronze.stores' AS table_name, store_nbr AS key, COUNT(*) AS cnt\n",
    "FROM bronze.stores GROUP BY store_nbr HAVING COUNT(*) > 1\n",
    "UNION ALL\n",
    "SELECT 'bronze.books', isbn, COUNT(*)\n",
    "FROM bronze.books GROUP BY isbn HAVING COUNT(*) > 1\n",
    "UNION ALL\n",
    "SELECT 'bronze.online_orders', order_id, COUNT(*)\n",
    "FROM bronze.online_orders GROUP BY order_id HAVING COUNT(*) > 1\n",
    "UNION ALL\n",
    "SELECT 'bronze.instore_orders', order_id, COUNT(*)\n",
    "FROM bronze.instore_orders GROUP BY order_id HAVING COUNT(*) > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, spot-check a few rows to confirm the audit columns look correct. The `ingestion_timestamp` should reflect when you last ran the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT isbn, title, ingestion_timestamp, source_filename\n",
    "FROM bronze.books\n",
    "LIMIT 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SQL",
   "language": "sql",
   "name": "sql"
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}